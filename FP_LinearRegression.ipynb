{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imported libraries and function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "def get_train_data():\n",
    "    data = pd.read_csv('train.csv')\n",
    "\n",
    "    data[\"pickup_datetime\"] = pd.to_datetime(data[\"pickup_datetime\"])\n",
    "    data[\"dropoff_datetime\"] = pd.to_datetime(data[\"dropoff_datetime\"])\n",
    "    data['pick_year'] = data[\"pickup_datetime\"].dt.year\n",
    "    data['pick_month'] = data[\"pickup_datetime\"].dt.month\n",
    "    data['pick_day'] = data[\"pickup_datetime\"].dt.day\n",
    "\n",
    "    data['pickup_year'] = data[\"pickup_datetime\"].dt.year\n",
    "    data['pickup_month'] = data[\"pickup_datetime\"].dt.month\n",
    "    data['pickup_day'] = data[\"pickup_datetime\"].dt.day\n",
    "\n",
    "    data['dropoff_year'] = data[\"dropoff_datetime\"].dt.year\n",
    "    data['dropoff_month'] = data[\"dropoff_datetime\"].dt.month\n",
    "    data['dropoff_day'] = data[\"dropoff_datetime\"].dt.day\n",
    "\n",
    "    pickup_hour =  data[\"pickup_datetime\"].dt.hour\n",
    "    pickup_minute = data[\"pickup_datetime\"].dt.minute\n",
    "    pickup_second = data[\"pickup_datetime\"].dt.second\n",
    "\n",
    "    dropoff_hour =  data[\"dropoff_datetime\"].dt.hour\n",
    "    dropoff_minute = data[\"dropoff_datetime\"].dt.minute\n",
    "    dropoff_second = data[\"dropoff_datetime\"].dt.second\n",
    "\n",
    "    pickup_time = pickup_hour*3600+pickup_minute*60+pickup_second\n",
    "    data['pickup_time'] = pickup_time\n",
    "\n",
    "    dropoff_time = dropoff_hour*3600+dropoff_minute*60+dropoff_second\n",
    "    data['dropoff_time'] = dropoff_time\n",
    "\n",
    "    data = data.drop(['pick_month'],axis=1)\n",
    "    data =data.drop(['pick_day'],axis=1)\n",
    "    data =data.drop(['pick_year'],axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_test_data():\n",
    "    data = pd.read_csv('test.csv')\n",
    "\n",
    "    data[\"pickup_datetime\"] = pd.to_datetime(data[\"pickup_datetime\"])\n",
    "    data['pick_year'] = data[\"pickup_datetime\"].dt.year\n",
    "    data['pick_month'] = data[\"pickup_datetime\"].dt.month\n",
    "    data['pick_day'] = data[\"pickup_datetime\"].dt.day\n",
    "\n",
    "    data['pickup_year'] = data[\"pickup_datetime\"].dt.year\n",
    "    data['pickup_month'] = data[\"pickup_datetime\"].dt.month\n",
    "    data['pickup_day'] = data[\"pickup_datetime\"].dt.day\n",
    "\n",
    "    pickup_hour =  data[\"pickup_datetime\"].dt.hour\n",
    "    pickup_minute = data[\"pickup_datetime\"].dt.minute\n",
    "    pickup_second = data[\"pickup_datetime\"].dt.second\n",
    "\n",
    "\n",
    "    pickup_time = pickup_hour*3600+pickup_minute*60+pickup_second\n",
    "    data['pickup_time'] = pickup_time\n",
    "\n",
    "    data = data.drop(['pick_month'],axis=1)\n",
    "    data =data.drop(['pick_day'],axis=1)\n",
    "    data =data.drop(['pick_year'],axis=1)\n",
    "    \n",
    "    return data\n",
    "\n",
    "from math import sin, cos, sqrt, atan2, radians\n",
    "\n",
    "# approximate radius of earth in km\n",
    "def get_L2(lat1,lon1,lat2,lon2):\n",
    "    R = 6373.0\n",
    "\n",
    "    lat1 = radians(lat1)\n",
    "    lon1 = radians(lon1)\n",
    "    lat2 = radians(lat2)\n",
    "    lon2 = radians(lon2)\n",
    "\n",
    "    dlon = lon2 - lon1\n",
    "    dlat = lat2 - lat1\n",
    "\n",
    "    a = sin(dlat / 2)**2 + cos(lat1) * cos(lat2) * sin(dlon / 2)**2\n",
    "    c = 2 * atan2(sqrt(a), sqrt(1 - a))\n",
    "\n",
    "    distance = R * c\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe for LR\n",
    "### Create Standard x and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read data frame\n",
    "df_train = get_train_data()\n",
    "df_test = get_test_data()\n",
    "\n",
    "# Drop id, vendor_id, dropoff_month, dropoff_day, dropoff_time, store_and_fwd_flag\n",
    "df_train= df_train.drop(['id'],axis=1)\n",
    "df_train= df_train.drop(['vendor_id'],axis=1)\n",
    "df_train= df_train.drop(['dropoff_month'],axis=1)\n",
    "df_train= df_train.drop(['dropoff_day'],axis=1)\n",
    "df_train= df_train.drop(['dropoff_year'],axis=1)\n",
    "df_train= df_train.drop(['dropoff_time'],axis=1)\n",
    "df_train= df_train.drop(['store_and_fwd_flag'],axis=1)\n",
    "df_train= df_train.drop(['pickup_datetime'],axis=1)\n",
    "df_train= df_train.drop(['dropoff_datetime'],axis=1)\n",
    "\n",
    "test_id = df_test['id']\n",
    "df_test= df_test.drop(['id'],axis=1)\n",
    "df_test= df_test.drop(['vendor_id'],axis=1)\n",
    "df_test= df_test.drop(['store_and_fwd_flag'],axis=1)\n",
    "df_test= df_test.drop(['pickup_datetime'],axis=1)\n",
    "\n",
    "\n",
    "# Make standard x,y\n",
    "train_y = df_train['trip_duration']\n",
    "train_x = df_train.drop(['trip_duration'],axis=1)\n",
    "\n",
    "\n",
    "test_x = df_test\n",
    "#test_id\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/scipy/linalg/basic.py:1226: RuntimeWarning: internal gelsd driver lwork query error, required iwork dimension not returned. This is likely the result of LAPACK bug 0038, fixed in LAPACK 3.2.2 (released July 21, 2010). Falling back to 'gelss' driver.\n",
      "  warnings.warn(mesg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5097781080112327\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "# Timer\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Actual training\n",
    "regr.fit(train_x, train_y)\n",
    "pred_y = regr.predict(test_x)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print (elapsed)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic -predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.86725\n"
     ]
    }
   ],
   "source": [
    "# Make the dataframe\n",
    "duration_content = np.rint(pred_y)\n",
    "id_content = np.array(test_id)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id':id_content,\n",
    "    'trip_duration':duration_content\n",
    "})\n",
    "\n",
    "# Create the csv file\n",
    "df.to_csv('basic_LR.csv',index= False)\n",
    "\n",
    "# Now, upload the csv file to\n",
    "# https://www.kaggle.com/c/nyc-taxi-trip-duration/submit\n",
    "print(\"Score is 0.86725\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6513427649915684\n"
     ]
    }
   ],
   "source": [
    "x = train_x.copy()\n",
    "y = train_y.copy()\n",
    "test = test_x.copy()\n",
    "\n",
    "df_lat1 = np.array(x['pickup_latitude'])\n",
    "df_lon1 = np.array(x['pickup_longitude'])\n",
    "df_lat2 = np.array(x['dropoff_latitude'])\n",
    "df_lon2 = np.array(x['dropoff_longitude'])\n",
    "\n",
    "dft_lat1 = np.array(test['pickup_latitude'])\n",
    "dft_lon1 = np.array(test['pickup_longitude'])\n",
    "dft_lat2 = np.array(test['dropoff_latitude'])\n",
    "dft_lon2 = np.array(test['dropoff_longitude'])\n",
    "\n",
    "L2 = []\n",
    "for idx in range(len(df_lat1)):\n",
    "    lat1 = df_lat1[idx]\n",
    "    lon1 = df_lon1[idx]\n",
    "    lat2 = df_lat2[idx]\n",
    "    lon2 = df_lon2[idx]\n",
    "    L2.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "L2_t = []\n",
    "for idx in range(len(dft_lat1)):\n",
    "    lat1 = dft_lat1[idx]\n",
    "    lon1 = dft_lon1[idx]\n",
    "    lat2 = dft_lat2[idx]\n",
    "    lon2 = dft_lon2[idx]\n",
    "    L2_t.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "x['L2'] = L2\n",
    "test['L2'] = L2_t\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "# Timer\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Actual training\n",
    "regr.fit(x, y)\n",
    "pred_y = regr.predict(test)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print (elapsed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L2 - predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.68746\n"
     ]
    }
   ],
   "source": [
    "# Make the dataframe\n",
    "\n",
    "duration_content = np.rint(pred_y)\n",
    "id_content = np.array(test_id)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id':id_content,\n",
    "    'trip_duration':duration_content\n",
    "})\n",
    "\n",
    "# Create the csv file\n",
    "df.to_csv('L2_LR.csv',index= False)\n",
    "\n",
    "# Now, upload the csv file to\n",
    "# https://www.kaggle.com/c/nyc-taxi-trip-duration/submit\n",
    "print(\"Score is 0.68746\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### L1 - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6367131829902064\n"
     ]
    }
   ],
   "source": [
    "x = train_x.copy()\n",
    "y = train_y.copy()\n",
    "test = test_x.copy()\n",
    "\n",
    "df_lat1 = np.array(x['pickup_latitude'])\n",
    "df_lon1 = np.array(x['pickup_longitude'])\n",
    "df_lat2 = np.array(x['dropoff_latitude'])\n",
    "df_lon2 = np.array(x['dropoff_longitude'])\n",
    "\n",
    "dft_lat1 = np.array(test['pickup_latitude'])\n",
    "dft_lon1 = np.array(test['pickup_longitude'])\n",
    "dft_lat2 = np.array(test['dropoff_latitude'])\n",
    "dft_lon2 = np.array(test['dropoff_longitude'])\n",
    "\n",
    "L1 = []\n",
    "for idx in range(len(df_lat1)):\n",
    "    lat1 = df_lat1[idx]\n",
    "    lon1 = df_lon1[idx]\n",
    "    lat2 = df_lat2[idx]\n",
    "    lon2 = df_lon2[idx]\n",
    "    L1.append(abs(lat1-lat2)+abs(lon1-lon2))\n",
    "L1_t = []\n",
    "for idx in range(len(dft_lat1)):\n",
    "    lat1 = dft_lat1[idx]\n",
    "    lon1 = dft_lon1[idx]\n",
    "    lat2 = dft_lat2[idx]\n",
    "    lon2 = dft_lon2[idx]\n",
    "    L1_t.append(abs(lat1-lat2)+abs(lon1-lon2))\n",
    "x['L1'] = L1\n",
    "test['L1'] = L1_t\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "# Timer\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "# Actual training\n",
    "regr.fit(x, y)\n",
    "pred_y = regr.predict(test)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print (elapsed)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.69480\n"
     ]
    }
   ],
   "source": [
    "# Make the dataframe\n",
    "\n",
    "duration_content = np.rint(pred_y)\n",
    "id_content = np.array(test_id)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id':id_content,\n",
    "    'trip_duration':duration_content\n",
    "})\n",
    "\n",
    "# Create the csv file\n",
    "df.to_csv('L1_LR.csv',index= False)\n",
    "\n",
    "# Now, upload the csv file to\n",
    "# https://www.kaggle.com/c/nyc-taxi-trip-duration/submit\n",
    "print(\"Score is 0.69480\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial(degree2) with L2 - train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.589969166001538\n",
      "64.12128323598881\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\npoly_2 = PolynomialFeatures(degree=2)\\nx = poly.fit_transform(x)\\ntest = poly.fit_transform(test)\\n\\nclf = linear_model.LinearRegression()\\nimport timeit\\nstart_time = timeit.default_timer()\\nclf.fit(x_, y)\\npred_y = clf.predict(test_)\\nelapsed = timeit.default_timer() - start_time\\nprint (elapsed)\\n\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = train_x.copy()\n",
    "y = train_y.copy()\n",
    "test = test_x.copy()\n",
    "\n",
    "df_lat1 = np.array(x['pickup_latitude'])\n",
    "df_lon1 = np.array(x['pickup_longitude'])\n",
    "df_lat2 = np.array(x['dropoff_latitude'])\n",
    "df_lon2 = np.array(x['dropoff_longitude'])\n",
    "\n",
    "dft_lat1 = np.array(test['pickup_latitude'])\n",
    "dft_lon1 = np.array(test['pickup_longitude'])\n",
    "dft_lat2 = np.array(test['dropoff_latitude'])\n",
    "dft_lon2 = np.array(test['dropoff_longitude'])\n",
    "\n",
    "L2 = []\n",
    "for idx in range(len(df_lat1)):\n",
    "    lat1 = df_lat1[idx]\n",
    "    lon1 = df_lon1[idx]\n",
    "    lat2 = df_lat2[idx]\n",
    "    lon2 = df_lon2[idx]\n",
    "    L2.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "L2_t = []\n",
    "for idx in range(len(dft_lat1)):\n",
    "    lat1 = dft_lat1[idx]\n",
    "    lon1 = dft_lon1[idx]\n",
    "    lat2 = dft_lat2[idx]\n",
    "    lon2 = dft_lon2[idx]\n",
    "    L2_t.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "x['L2'] = L2\n",
    "test['L2'] = L2_t\n",
    "\n",
    "degree_list = [2,3]\n",
    "\n",
    "for degree in degree_list:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_ = poly.fit_transform(x)\n",
    "    test_ = poly.fit_transform(test)\n",
    "    clf = linear_model.LinearRegression()\n",
    "    import timeit\n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(x_, y)\n",
    "    pred_y = clf.predict(test_)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print (elapsed)\n",
    "    duration_content = np.rint(pred_y)\n",
    "    id_content = np.array(test_id)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id':id_content,\n",
    "        'trip_duration':duration_content\n",
    "    })\n",
    "\n",
    "    # Create the csv file\n",
    "    filename = 'PolyL2_LR_' + str(degree) + '.csv'\n",
    "    df.to_csv(filename,index= False)\n",
    "\"\"\"\n",
    "poly_2 = PolynomialFeatures(degree=2)\n",
    "x = poly.fit_transform(x)\n",
    "test = poly.fit_transform(test)\n",
    "\n",
    "clf = linear_model.LinearRegression()\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "clf.fit(x_, y)\n",
    "pred_y = clf.predict(test_)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print (elapsed)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score is 0.63158\n"
     ]
    }
   ],
   "source": [
    "# Make the dataframe\n",
    "\n",
    "duration_content = np.rint(pred_y)\n",
    "id_content = np.array(test_id)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id':id_content,\n",
    "    'trip_duration':duration_content\n",
    "})\n",
    "\n",
    "# Create the csv file\n",
    "df.to_csv('PolyL2_LR.csv',index= False)\n",
    "\n",
    "# Now, upload the csv file to\n",
    "# https://www.kaggle.com/c/nyc-taxi-trip-duration/submit\n",
    "print(\"Score is 0.63158\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso with L2 -Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309.305736476992\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = train_x.copy()\n",
    "y = train_y.copy()\n",
    "test = test_x.copy()\n",
    "\n",
    "df_lat1 = np.array(x['pickup_latitude'])\n",
    "df_lon1 = np.array(x['pickup_longitude'])\n",
    "df_lat2 = np.array(x['dropoff_latitude'])\n",
    "df_lon2 = np.array(x['dropoff_longitude'])\n",
    "\n",
    "dft_lat1 = np.array(test['pickup_latitude'])\n",
    "dft_lon1 = np.array(test['pickup_longitude'])\n",
    "dft_lat2 = np.array(test['dropoff_latitude'])\n",
    "dft_lon2 = np.array(test['dropoff_longitude'])\n",
    "\n",
    "L2 = []\n",
    "for idx in range(len(df_lat1)):\n",
    "    lat1 = df_lat1[idx]\n",
    "    lon1 = df_lon1[idx]\n",
    "    lat2 = df_lat2[idx]\n",
    "    lon2 = df_lon2[idx]\n",
    "    L2.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "L2_t = []\n",
    "for idx in range(len(dft_lat1)):\n",
    "    lat1 = dft_lat1[idx]\n",
    "    lon1 = dft_lon1[idx]\n",
    "    lat2 = dft_lat2[idx]\n",
    "    lon2 = dft_lon2[idx]\n",
    "    L2_t.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "x['L2'] = L2\n",
    "test['L2'] = L2_t\n",
    "\n",
    "degree_list = [2]\n",
    "\n",
    "for degree in degree_list:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_ = poly.fit_transform(x)\n",
    "    test_ = poly.fit_transform(test)\n",
    "    clf = linear_model.Lasso(alpha=0.1)\n",
    "    import timeit\n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(x_, y)\n",
    "    pred_y = clf.predict(test_)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print (elapsed)\n",
    "    duration_content = np.rint(pred_y)\n",
    "    id_content = np.array(test_id)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id':id_content,\n",
    "        'trip_duration':duration_content\n",
    "    })\n",
    "\n",
    "    # Create the csv file\n",
    "    filename = 'Lasso' + str(degree) + '.csv'\n",
    "    df.to_csv(filename,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.64415\n"
     ]
    }
   ],
   "source": [
    "print(\"0.64415\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso(degree 3) with L2 -Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1553.5645713300037\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = train_x.copy()\n",
    "y = train_y.copy()\n",
    "test = test_x.copy()\n",
    "\n",
    "df_lat1 = np.array(x['pickup_latitude'])\n",
    "df_lon1 = np.array(x['pickup_longitude'])\n",
    "df_lat2 = np.array(x['dropoff_latitude'])\n",
    "df_lon2 = np.array(x['dropoff_longitude'])\n",
    "\n",
    "dft_lat1 = np.array(test['pickup_latitude'])\n",
    "dft_lon1 = np.array(test['pickup_longitude'])\n",
    "dft_lat2 = np.array(test['dropoff_latitude'])\n",
    "dft_lon2 = np.array(test['dropoff_longitude'])\n",
    "\n",
    "L2 = []\n",
    "for idx in range(len(df_lat1)):\n",
    "    lat1 = df_lat1[idx]\n",
    "    lon1 = df_lon1[idx]\n",
    "    lat2 = df_lat2[idx]\n",
    "    lon2 = df_lon2[idx]\n",
    "    L2.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "L2_t = []\n",
    "for idx in range(len(dft_lat1)):\n",
    "    lat1 = dft_lat1[idx]\n",
    "    lon1 = dft_lon1[idx]\n",
    "    lat2 = dft_lat2[idx]\n",
    "    lon2 = dft_lon2[idx]\n",
    "    L2_t.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "x['L2'] = L2\n",
    "test['L2'] = L2_t\n",
    "\n",
    "degree_list = [3]\n",
    "\n",
    "for degree in degree_list:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_ = poly.fit_transform(x)\n",
    "    test_ = poly.fit_transform(test)\n",
    "    clf = linear_model.Lasso(alpha=0.1)\n",
    "    import timeit\n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(x_, y)\n",
    "    pred_y = clf.predict(test_)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print (elapsed)\n",
    "    duration_content = np.rint(pred_y)\n",
    "    id_content = np.array(test_id)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id':id_content,\n",
    "        'trip_duration':duration_content\n",
    "    })\n",
    "\n",
    "    # Create the csv file\n",
    "    filename = 'Lasso' + str(degree) + '.csv'\n",
    "    df.to_csv(filename,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.63360\n"
     ]
    }
   ],
   "source": [
    "print(\"0.63360\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "/Users/wayne/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/coordinate_descent.py:491: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha is 10.0\n",
      "191.65076293601305\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x = train_x.copy()\n",
    "y = train_y.copy()\n",
    "test = test_x.copy()\n",
    "\n",
    "df_lat1 = np.array(x['pickup_latitude'])\n",
    "df_lon1 = np.array(x['pickup_longitude'])\n",
    "df_lat2 = np.array(x['dropoff_latitude'])\n",
    "df_lon2 = np.array(x['dropoff_longitude'])\n",
    "\n",
    "dft_lat1 = np.array(test['pickup_latitude'])\n",
    "dft_lon1 = np.array(test['pickup_longitude'])\n",
    "dft_lat2 = np.array(test['dropoff_latitude'])\n",
    "dft_lon2 = np.array(test['dropoff_longitude'])\n",
    "\n",
    "L2 = []\n",
    "for idx in range(len(df_lat1)):\n",
    "    lat1 = df_lat1[idx]\n",
    "    lon1 = df_lon1[idx]\n",
    "    lat2 = df_lat2[idx]\n",
    "    lon2 = df_lon2[idx]\n",
    "    L2.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "L2_t = []\n",
    "for idx in range(len(dft_lat1)):\n",
    "    lat1 = dft_lat1[idx]\n",
    "    lon1 = dft_lon1[idx]\n",
    "    lat2 = dft_lat2[idx]\n",
    "    lon2 = dft_lon2[idx]\n",
    "    L2_t.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "x['L2'] = L2\n",
    "test['L2'] = L2_t\n",
    "\n",
    "degree_list = [2]\n",
    "\n",
    "for degree in degree_list:\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_ = poly.fit_transform(x)\n",
    "    test_ = poly.fit_transform(test)\n",
    "    cv_list = [0.01,0.1,0.5,1.0,2.0,5.0,10.0]\n",
    "    score_list =[]\n",
    "    for cv in cv_list:\n",
    "        clf = linear_model.Lasso(alpha=cv)\n",
    "        scores = cross_val_score(clf, x_, y, cv=5)\n",
    "        score_list.append(scores.mean())\n",
    "    max_idx = np.argmax(np.array(score_list))\n",
    "    print(\"best alpha is {}\".format(cv_list[max_idx]))\n",
    "    import timeit\n",
    "    clf = linear_model.Lasso(alpha=cv_list[max_idx])\n",
    "    start_time = timeit.default_timer()\n",
    "    clf.fit(x_, y)\n",
    "    pred_y = clf.predict(test_)\n",
    "    elapsed = timeit.default_timer() - start_time\n",
    "    print (elapsed)\n",
    "    duration_content = np.rint(pred_y)\n",
    "    id_content = np.array(test_id)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id':id_content,\n",
    "        'trip_duration':duration_content\n",
    "    })\n",
    "\n",
    "    # Create the csv file\n",
    "    filename = 'Lasso' + str(degree) + '.csv'\n",
    "    df.to_csv(filename,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ridge' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-6aa9274a045c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mduration_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mid_content\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Ridge' is not defined"
     ]
    }
   ],
   "source": [
    "clf = Ridge(alpha=0.1)\n",
    "clf.fit(x_, y) \n",
    "pred_y = clf.predict(test_)\n",
    "duration_content = np.rint(pred_y)\n",
    "id_content = np.array(test_id)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'id':id_content,\n",
    "    'trip_duration':duration_content\n",
    "})\n",
    "\n",
    "# Create the csv file\n",
    "filename = 'Ridge' + str(degree) + '.csv'\n",
    "df.to_csv(filename,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "x = train_x.copy()\n",
    "y = train_y.copy()\n",
    "test = test_x.copy()\n",
    "\n",
    "df_lat1 = np.array(x['pickup_latitude'])\n",
    "df_lon1 = np.array(x['pickup_longitude'])\n",
    "df_lat2 = np.array(x['dropoff_latitude'])\n",
    "df_lon2 = np.array(x['dropoff_longitude'])\n",
    "\n",
    "dft_lat1 = np.array(test['pickup_latitude'])\n",
    "dft_lon1 = np.array(test['pickup_longitude'])\n",
    "dft_lat2 = np.array(test['dropoff_latitude'])\n",
    "dft_lon2 = np.array(test['dropoff_longitude'])\n",
    "\n",
    "L2 = []\n",
    "for idx in range(len(df_lat1)):\n",
    "    lat1 = df_lat1[idx]\n",
    "    lon1 = df_lon1[idx]\n",
    "    lat2 = df_lat2[idx]\n",
    "    lon2 = df_lon2[idx]\n",
    "    L2.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "L2_t = []\n",
    "for idx in range(len(dft_lat1)):\n",
    "    lat1 = dft_lat1[idx]\n",
    "    lon1 = dft_lon1[idx]\n",
    "    lat2 = dft_lat2[idx]\n",
    "    lon2 = dft_lon2[idx]\n",
    "    L2_t.append(get_L2(lat1,lon1,lat2,lon2))\n",
    "x['L2'] = L2\n",
    "test['L2'] = L2_t\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "59.79876787198009\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "reg = MLPRegressor(hidden_layer_sizes=(20,),  activation='relu', solver='adam',    alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=False, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "\n",
    "import timeit\n",
    "start_time = timeit.default_timer()\n",
    "reg = reg.fit(x, y)\n",
    "pred_y = reg.predict(test)\n",
    "elapsed = timeit.default_timer() - start_time\n",
    "print (elapsed)\n",
    "duration_content = np.rint(pred_y)\n",
    "id_content = np.array(test_id)\n",
    "\n",
    "df = pd.DataFrame({\n",
    "     'id':id_content,\n",
    "     'trip_duration':duration_content\n",
    "})\n",
    "\n",
    "# Create the csv file\n",
    "filename = 'MLPR_test' + str(degree) + '.csv'\n",
    "df.to_csv(filename,index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
