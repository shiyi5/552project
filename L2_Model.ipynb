{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load functions and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model\n",
    "import numpy as np\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.svm import LinearSVR\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from xgboost import XGBRegressor\n",
    "import timeit\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "\n",
    "def get_csv(filename,pred_y):\n",
    "    #print(pred_y.shape)\n",
    "    duration_content = np.rint(pred_y)\n",
    "    #duration_content = np.array(duration_content)\n",
    "    #print(duration_content.shape)\n",
    "    \n",
    "    #print(duration_content)\n",
    "    id_content = np.array(test_id)\n",
    "    #print(id_content.shape)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id':id_content,\n",
    "        'trip_duration':duration_content\n",
    "    })\n",
    "\n",
    "    # Create the csv file\n",
    "    fn = filename + '.csv'\n",
    "    df.to_csv(fn,index= False)\n",
    "    \n",
    "    \n",
    "def get_csv_cluster(filename,pred_y,testid):\n",
    "    #print(pred_y.shape)\n",
    "    duration_content = np.rint(pred_y)\n",
    "    #duration_content = np.array(duration_content)\n",
    "    #print(duration_content.shape)\n",
    "    \n",
    "    #print(duration_content)\n",
    "    id_content = np.array(testid)\n",
    "    #print(id_content.shape)\n",
    "\n",
    "    df = pd.DataFrame({\n",
    "        'id':id_content,\n",
    "        'trip_duration':duration_content\n",
    "    })\n",
    "\n",
    "    # Create the csv file\n",
    "    fn = filename + '.csv'\n",
    "    df.to_csv(fn,index= False)\n",
    "    \n",
    "    \n",
    "def get_poly(degree,x,test):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    x_ = poly.fit_transform(x)\n",
    "    test_ = poly.fit_transform(test)\n",
    "    \n",
    "    return x_,test_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting X, Y (Modify filename to get different version of data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "train_x = pd.read_csv('L2_train_x.csv')   # Change this\n",
    "train_y = pd.read_csv('train_y.csv',header = -1)   # Change this\n",
    "test_x = pd.read_csv('L2_test.csv')  # Change this\n",
    "test_id = test['id']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Various regressions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression\n",
    "0.869 1159 <br>\n",
    "fit time is: 0.5949127580024651<br>\n",
    "predict time is: 0.01478029000281822<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 0.8764537219976773\n",
      "predict time is: 0.047067132996744476\n"
     ]
    }
   ],
   "source": [
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y = regr.predict(test_x)\n",
    "pred_y = pred_y.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_LR',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Polynomial Regression\n",
    "0.84502 1151 <br>\n",
    "fit time is: 12.516197695003939 <br>\n",
    "predict time is: 0.01478029000281822 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 17.438511497995933\n",
      "predict time is: 0.047067132996744476\n"
     ]
    }
   ],
   "source": [
    "\n",
    "x_,test_ = get_poly(2,train_x,test_x)\n",
    "\n",
    "regr = linear_model.LinearRegression()\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr.fit(x_, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "#start_time = timeit.default_timer()\n",
    "pred_y = regr.predict(test_)\n",
    "pred_y = pred_y.flatten()\n",
    "#predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_PR',pred_y)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lasso\n",
    "\n",
    "0.87012 1161<br>\n",
    "fit time is: 0.6580201340038911 <br>\n",
    "predict time is: 0.01415189600083977<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 1.0064515250051045\n",
      "predict time is: 0.0634287829961977\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "#clf = linear_model.Lasso(alpha=cv_list[max_idx])\n",
    "clf = linear_model.Lasso(alpha=1.0)\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "clf.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred_y = clf.predict(test_x)\n",
    "pred_y = pred_y.flatten()\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_LASSO',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ridge\n",
    "0.86982 1159\n",
    "fit time is: 0.3165850510049495 <br>\n",
    "predict time is: 0.010517886999878101 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 0.3713842180004576\n",
      "predict time is: 0.038410000001022127\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = Ridge(alpha=1.0)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "clf.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred_y = clf.predict(test_x)\n",
    "pred_y = pred_y.flatten()\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_Ridge',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "0.88073  <br>\n",
    "fit time is: 38.12283402299363 <br>\n",
    "predict time is: 1.2900892430043314 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 57.55101072999241\n",
      "predict time is: 1.1541626760008512\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = MLPRegressor(hidden_layer_sizes=(100,),  activation='relu', solver='adam',    alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "train_y= np.array(train_y).flatten()\n",
    "clf.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred_y = clf.predict(test_x)\n",
    "#pred_y = pred_y.flatten()\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_NN',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Regression\n",
    "0.61829 <br>\n",
    "fit time is: 24.759334297996247 <br>\n",
    "predict time is: 0.5807069809961831 <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 31.446521985999425\n",
      "predict time is: 0.5737381479993928\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = DecisionTreeRegressor()\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "train_y= np.array(train_y).flatten()\n",
    "clf.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred_y = clf.predict(test_x)\n",
    "#pred_y = pred_y.flatten()\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_DTR',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EN\n",
    "0.8891\n",
    "fit time is: 0.673529542000324<BR>\n",
    "predict time is: 0.0554104409966385<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 0.7259531390009215\n",
      "predict time is: 0.044924722002178896\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = ElasticNet(random_state=0)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "train_y= np.array(train_y).flatten()\n",
    "clf.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred_y = clf.predict(test_x)\n",
    "#pred_y = pred_y.flatten()\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_ENet',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RF Regression\n",
    "0.82194<BR>\n",
    "fit time is: 14.449963496997952<BR>\n",
    "predict time is: 0.2338456350043998<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 19.596968042002118\n",
      "predict time is: 0.1815003660012735\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "train_y= np.array(train_y).flatten()\n",
    "clf.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred_y = clf.predict(test_x)\n",
    "#pred_y = pred_y.flatten()\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_RFR',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 155.30083064900828\n",
      "predict time is: 1.497325442993315\n"
     ]
    }
   ],
   "source": [
    "\n",
    "clf = XGBRegressor()\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "train_y= np.array(train_y).flatten()\n",
    "clf.fit(train_x, train_y)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "pred_y = clf.predict(test_x)\n",
    "#pred_y = pred_y.flatten()\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv('SUB_L2_XGB',pred_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find best k for the cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For n_clusters=2, The Silhouette Coefficient with a size of 10000 is 0.6064878787520772 \n",
      "For n_clusters=3, The Silhouette Coefficient with a size of 10000 is 0.5850855793147302 \n",
      "For n_clusters=4, The Silhouette Coefficient with a size of 10000 is 0.5844339218292547 \n",
      "For n_clusters=5, The Silhouette Coefficient with a size of 10000 is 0.5765276227201171 \n",
      "For n_clusters=6, The Silhouette Coefficient with a size of 10000 is 0.5686673676429781 \n"
     ]
    }
   ],
   "source": [
    "num_list = [2,3,4,5,6]\n",
    "size_list = [10000]\n",
    "results = []\n",
    "for n_cluster in num_list:\n",
    "    kmeans = KMeans(n_clusters=n_cluster).fit(train_x)\n",
    "    label = kmeans.fit_predict(train_x)\n",
    "    for size in size_list:\n",
    "        sil_coeff = silhouette_score(train_x[:size], label[:size], metric='euclidean')\n",
    "        results.append(sil_coeff)\n",
    "        #store.append(sil_coeff)\n",
    "        print(\"For n_clusters={}, The Silhouette Coefficient with a size of {} is {} \".format(n_cluster, size,sil_coeff))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Split training set based on cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "best_k = num_list[np.argmax(np.array(results))]\n",
    "print(best_k)\n",
    "\n",
    "kmeans = KMeans(n_clusters=best_k).fit(train_x)\n",
    "labels = kmeans.predict(train_x)\n",
    "#print(labels)\n",
    "\n",
    "train_x_cluster = train_x.copy()\n",
    "\n",
    "train_x_cluster['cluster'] = labels\n",
    "train_x_cluster['duration'] = train_y\n",
    "\n",
    "mask = train_x_cluster['cluster'] ==0\n",
    "train_x_c0 = train_x_cluster[mask]\n",
    "train_x_c1 = train_x_cluster[~mask]\n",
    "\n",
    "\n",
    "train_y_c0 = train_x_c0['duration']\n",
    "train_y_c1 = train_x_c1['duration']\n",
    "train_x_c0 = train_x_c0.drop(['duration'],axis=1)\n",
    "train_x_c1 = train_x_c1.drop(['duration'],axis=1)\n",
    "\n",
    "predict_labels = kmeans.predict(test_x)\n",
    "test_x_temp = test_x.copy()\n",
    "test_x_temp['cluster'] = predict_labels\n",
    "test_x_temp['testid'] = test_id\n",
    "\n",
    "\n",
    "\n",
    "mask = test_x_temp['cluster'] ==0\n",
    "test_x_c0 = test_x_temp[mask]\n",
    "test_x_c1 = test_x_temp[~mask]\n",
    "\n",
    "test_id_c0 = test_x_c0['testid']\n",
    "test_x_c0 = test_x_c0.drop(['testid'],axis=1)\n",
    "test_id_c1 = test_x_c1['testid']\n",
    "test_x_c1 = test_x_c1.drop(['testid'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Train Linear\n",
    "From 0.869  to 0.86137"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 0.673505805003515\n",
      "predict time is: 0.058164975002000574\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr1 = linear_model.LinearRegression()\n",
    "regr2 = linear_model.LinearRegression()\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_LR_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Train PR\n",
    "From 0.84502 to 0.81918"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 18.851366661998327\n",
      "predict time is: 0.09462343699851772\n"
     ]
    }
   ],
   "source": [
    "x_,test_ = get_poly(2,train_x_c0,test_x_c0)\n",
    "x2_,test2_ = get_poly(2,train_x_c1,test_x_c1)\n",
    "\n",
    "\n",
    "regr1 = linear_model.LinearRegression()\n",
    "regr2 = linear_model.LinearRegression()\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(x_, train_y_c0)\n",
    "regr2.fit(x2_, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test2_)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_PR_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReTrain Lasso\n",
    "0.87012 to 0.86344"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 0.8685131969978102\n",
      "predict time is: 0.05733207699813647\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr1 = linear_model.Lasso(alpha=1.0)\n",
    "regr2 = linear_model.Lasso(alpha=1.0)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_LASSO_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReTrain Ridge\n",
    "From 0.86982 to 0.86138"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 0.33969793200230924\n",
      "predict time is: 0.04472315000020899\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr1 = Ridge(alpha=1.0)\n",
    "regr2 = Ridge(alpha=1.0)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_Ridge_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT NN\n",
    "From 0.88073 to 0.87623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 31.92348358799063\n",
      "predict time is: 0.814805548012373\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr1 =  MLPRegressor(hidden_layer_sizes=(100,),  activation='relu', solver='adam',    alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "regr2 =  MLPRegressor(hidden_layer_sizes=(100,),  activation='relu', solver='adam',    alpha=0.001,batch_size='auto',\n",
    "               learning_rate='constant', learning_rate_init=0.01, power_t=0.5, max_iter=1000, shuffle=True,\n",
    "               random_state=None, tol=0.0001, verbose=False, warm_start=False, momentum=0.9,\n",
    "               nesterovs_momentum=True, early_stopping=True, validation_fraction=0.1, beta_1=0.9, beta_2=0.999,\n",
    "               epsilon=1e-08)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_NN_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT DTR\n",
    "From 0.61829 to 0.62575"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 25.743130446004216\n",
      "predict time is: 0.49891954199119937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr1 = DecisionTreeRegressor()\n",
    "regr2 = DecisionTreeRegressor()\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_DTR_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT EN\n",
    "0.88832"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 0.6261870859962073\n",
      "predict time is: 0.06454465000570053\n"
     ]
    }
   ],
   "source": [
    "\n",
    "regr1 = ElasticNet(random_state=0)\n",
    "regr2 = ElasticNet(random_state=0)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_ENet_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT RF\n",
    "0.82167<BR>\n",
    "fit time is: 14.623066553998797 <BR>\n",
    "predict time is: 0.13730818399926648<BR>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 18.039448908995837\n",
      "predict time is: 0.1503933460044209\n"
     ]
    }
   ],
   "source": [
    "regr1 = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "regr2 = RandomForestRegressor(max_depth=2, random_state=0)\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_RF_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RT XBG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fit time is: 127.65505521399609\n",
      "predict time is: 1.4521665909996955\n"
     ]
    }
   ],
   "source": [
    "regr1 = XGBRegressor()\n",
    "regr2 = XGBRegressor()\n",
    "\n",
    "# Actual training\n",
    "start_time = timeit.default_timer()\n",
    "regr1.fit(train_x_c0, train_y_c0)\n",
    "regr2.fit(train_x_c1, train_y_c1)\n",
    "fit_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "start_time = timeit.default_timer()\n",
    "\n",
    "pred_y1 = regr1.predict(test_x_c0)\n",
    "pred_y1 = pred_y1.flatten()\n",
    "\n",
    "pred_y2 = regr2.predict(test_x_c1)\n",
    "pred_y2 = pred_y2.flatten()\n",
    "\n",
    "predict_elapsed = timeit.default_timer() - start_time\n",
    "\n",
    "pred = np.append(pred_y1,pred_y2)\n",
    "testid = np.append(test_id_c0,test_id_c1)\n",
    "\n",
    "print (\"fit time is: {}\".format(fit_elapsed))\n",
    "print (\"predict time is: {}\".format(predict_elapsed))\n",
    "\n",
    "\n",
    "get_csv_cluster('SUB_L2_XGB_Cluster',pred,testid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
